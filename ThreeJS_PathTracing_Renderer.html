<!DOCTYPE html>
<html lang="en">
	<head>
		<title>three.js PathTracing Renderer</title>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1">
		<style>
			
			body {
				color: #ffffff;
				font-family:Monospace;
				font-size:13px;
				text-align:center;
				font-weight: bold;

				background-color: #000000;
				margin: 0px;
				overflow: hidden;
			}

			#info {
				position: absolute;
				top: 0px; width: 100%;
				padding: 5px;
			}

			a {

				color: #ffffff;
			}

			#oldie a { color:#da0 }
		</style>
	</head>
	<body>

		<div id="container"></div>
		<div id="info"> three.js PathTracing Renderer</div>

		<!-- for Debugging -->
		<!-- <script src="js/three-r74.js"></script> -->
		
		<!-- for Release -->
		<script src="js/three-r75.min.js"></script>
		
		<script src="js/Detector.js"></script>
		<script src="js/stats.min.js"></script>
		
		
		<script id="screenVertexShader" type="x-shader/x-vertex">

varying vec2 vUv;

void main() {

	vUv = uv;
	gl_Position = vec4( position, 1.0 );

}

		</script>
		
		<script id="screenFragmentShader" type="x-shader/x-fragment">
		
precision highp float;
varying vec2 vUv;
uniform sampler2D tTexture0;

void main() {

	gl_FragColor = texture2D(tTexture0, vUv);
	
}
		
		</script>

		<script id="renderToTextureVertexShader" type="x-shader/x-vertex">
		
varying vec2 vUv;

void main()
{
	vUv = uv;
	gl_Position = vec4( position, 1.0 );
}

		</script>
		
		<script id="renderToTextureFragmentShader" type="x-shader/x-fragment">
				
precision highp float;

uniform vec2 resolution;
uniform float time;
uniform float uFrameCounter;
uniform float uULen;
uniform float uVLen;

uniform mat3 uCheckeredMaterialMatrix;
uniform mat3 uMirrorMaterialMatrix;
uniform mat3 uBlueMaterialMatrix;
uniform mat3 uWhiteMaterialMatrix;
uniform mat3 uGlassMaterialMatrix;

uniform mat4 uBoxMeshMatrix;
uniform mat4 uCameraMatrix;
uniform mat4 uLightMatrix[3];
uniform mat4 uSphereMeshMatrix[4];

uniform sampler2D tPreviousTexture;
varying vec2 vUv;


#define PI		  	  3.14159265359
#define RECIPROCAL_PI 		  0.31830988618
#define MAX_ITERATIONS	  	  100
#define MAX_REFLECTION_ITERATIONS 80
#define MAX_SHADOW_STEPS  	  45
#define MAX_BOUNCES  	          1
#define EPSILON           	  0.0001
#define MAX_RENDER_DISTANCE  	  50.0

#define HASHSCALE1                443.8975
#define HASHSCALE3 		  443.8975

#define saturate(a) clamp( a, 0.0, 1.0 )
float pow2( const in float x ) { return x*x; }
float pow3( const in float x ) { return x*x*x; }
float pow4( const in float x ) { float x2 = x*x; return x2*x2; }

// globals
vec3 lightPos[3];
vec3 light00Color = vec3(0.0);
vec3 light01Color = vec3(0.0);
vec3 light02Color = vec3(0.0);


// GLSL rand()-type hash functions

//  1 out, 1 in...
float hash11(float p)
{
	vec3 p3  = fract(vec3(p) * HASHSCALE1);
    p3 += dot(p3, p3.yzx + 19.19);
    return fract((p3.x + p3.y) * p3.z);
}

//  2 out, 2 in...
vec2 hash22(vec2 p)
{
	vec3 p3 = fract(vec3(p.xyx) * HASHSCALE3);
    p3 += dot(p3, p3.yzx+19.19);
    return fract(vec2((p3.x + p3.y)*p3.z, (p3.x+p3.z)*p3.y));
}

vec3 cosWeightedRandomHemisphereDirection( vec3 n, vec2 seed ) 
{

  	vec2 r = hash22( seed * time);
    
	vec3  uu = normalize( cross( n, vec3(0.0,1.0,1.0) ) );
	vec3  vv = cross( uu, n );
	
	float ra = sqrt(r.y);
	float rx = ra*cos(6.2831*r.x); 
	float ry = ra*sin(6.2831*r.x);
	float rz = sqrt( 1.0-r.y );
	vec3  rr = vec3( rx*uu + ry*vv + rz*n );
    
    	return normalize( rr );
}


// primitive distance functions
float distInfiniteGroundPlane( vec3 pos )
{
	return pos.y;
}

float distPlane( vec3 pos, vec3 normal, float distFromOrigin )
{
	return dot(pos, normal) + distFromOrigin;
}

float distSphere( vec3 pos, float radius )
{
    	return length( pos ) - radius;
}

float distBox( vec3 pos, vec3 scale )
{
    	return length( max( abs( pos ) - scale, vec3( 0.0 ) ) );
}

// distance field operations
float opUnion( float dist1, float dist2 )
{
    return min( dist1, dist2 );
}

float opSubtraction( float dist1, float dist2 )
{
    return max( -dist1, dist2 );
}

float opIntersection( float dist1, float dist2 )
{
    return max( dist1, dist2 );
}

// checkerBoard / chessBoard pattern
float chessBoard( vec3 pos, float scale )
{
    pos = floor( pos * scale ); 
    return mod( pos.x+pos.z, 2.0 );
}

// closest object
vec2 getDistToNearestObj( vec3 pos, bool checkForLights ) 
{   
	vec3 spherePos;
	vec3 boxPos;
	float dist, d1, d2, d3, d4;
	float testDist, closestDist;
	float materialID = -0.5;
	
    	// floor
    	//testDist = distPlane( pos, vec3(0,1,0), 0.0 );
	testDist = distInfiniteGroundPlane( pos );
	closestDist = testDist;
	
	if (testDist <= 0.1)
	{
		materialID = 0.0;
        }
	
	// lights
	if (checkForLights)
	{
		testDist = distSphere(pos - lightPos[0], 0.1);
		if (testDist < closestDist) {
			closestDist = testDist;
			materialID = -1.0;
		}
		testDist = distSphere(pos - lightPos[1], 0.1);
		if (testDist < closestDist) {
			closestDist = testDist;
			materialID = -2.0;
		}
		testDist = distSphere(pos - lightPos[2], 0.1);
		if (testDist < closestDist) {
			closestDist = testDist;
			materialID = -3.0;
		}
	}
	
    	// spheres
	// warp tracing sphere's position (pos) to sphereMesh's transform
    	spherePos = vec3( uSphereMeshMatrix[0] * vec4(pos,1.0) );
	testDist = distSphere(spherePos, 1.0);
	if (testDist < closestDist) {
		closestDist = testDist;
		materialID = 3.0;
	}
	spherePos = vec3( uSphereMeshMatrix[1] * vec4(pos,1.0) );
	testDist = distSphere(spherePos, 0.5);
	if (testDist < closestDist) {
		closestDist = testDist;
		materialID = 2.0;
	}
	spherePos = vec3( uSphereMeshMatrix[2] * vec4(pos,1.0) );
	testDist = distSphere(spherePos, 0.5);
	if (testDist < closestDist) {
		closestDist = testDist;
		materialID = 2.0;
	}
	spherePos = vec3( uSphereMeshMatrix[3] * vec4(pos,1.0) );
	testDist = distSphere(spherePos, 1.0);
	if (testDist < closestDist) {
		closestDist = testDist;
		materialID = 4.0;
	}
	
    	
    	// warp tracing sphere's position (pos) to boxMesh's transform
    	boxPos = vec3( uBoxMeshMatrix * vec4(pos,1.0) );
	
    	// boxes
    	d1 = distBox( boxPos, vec3(1.0) );
    	d2 = distBox( boxPos - vec3( sin(time)*1.5, 0.5, sin(time)*1.5 ), vec3(0.6,0.2,0.6) );
	//dist = min( dist, opUnion(d1,d2) );
	d3 = distSphere(boxPos, abs(sin(time*0.5)) * 1.6 );
        dist = opSubtraction(d3,d1);
        testDist = min( dist, d2 );
	if (testDist < closestDist) {
		closestDist = testDist;
		materialID = 1.0;
	}
   	
	return vec2(closestDist, materialID);
}


//Surface normal at the current position
vec3 computeSurfaceNormal( vec3 p )
{
    vec3 off = vec3(0.01, 0, 0);
    return normalize
    ( 
        vec3
        (
            getDistToNearestObj(p + off.xyz, false).x - getDistToNearestObj(p - off.xyz, false).x,
            getDistToNearestObj(p + off.zxy, false).x - getDistToNearestObj(p - off.zxy, false).x,
            getDistToNearestObj(p + off.yzx, false).x - getDistToNearestObj(p - off.yzx, false).x
        )
    );
}

mat3 getMaterialMatrix ( float materialID )
{
	mat3 currentMaterialMatrix;
	
     	     if (materialID == 0.0) currentMaterialMatrix = uCheckeredMaterialMatrix;
	else if (materialID == 1.0) currentMaterialMatrix = uBlueMaterialMatrix;
	else if (materialID == 2.0) currentMaterialMatrix = uMirrorMaterialMatrix;
	else if (materialID == 3.0) currentMaterialMatrix = uWhiteMaterialMatrix;
	else if (materialID == 4.0) currentMaterialMatrix = uGlassMaterialMatrix;
	
	return currentMaterialMatrix;
}

float calcAO( vec3 pos, vec3 nor )
{
	float occ = 0.0;
    	float sca = 1.0;
    	for( int i=0; i<3; i++ )
    	{
        	float hr = 0.01 + 0.12*float(i)/4.0;
        	vec3 aopos =  nor * hr + pos;
        	float dd = getDistToNearestObj( aopos, false ).x;
        	occ += -(dd-hr)*sca;
        	sca *= 0.95;
    	}
    	return clamp( 1.0 - 3.0*occ, 0.5, 1.0 );    
}

float softShadow( vec3 ro, vec3 rd )
{
	float res = 1.0;
    	float t = 0.03;//0.02
    	for( int i=0; i<MAX_SHADOW_STEPS; i++ )
    	{
		float h = getDistToNearestObj( ro + rd*t, false ).x;
		//if (h < EPSILON) break;
		res = min( res, h*50.0 / t );
		t += h;
		//if (t > 20.0) break;
    	}
    	return clamp( res, 0.1, 1.0 );
}

vec3 BRDF_Diffuse_Lambert( const in vec3 diffuseColor ) {

	return RECIPROCAL_PI * diffuseColor;

}

vec3 BRDF_Diffuse_OrenNayar( vec3 lightDirection, vec3 surfaceNormal, vec3 viewDirection, vec3 diffuseColor, float roughness, float albedo )
{
  
  	float LdotV = dot(lightDirection, viewDirection);
  	float NdotL = dot(lightDirection, surfaceNormal);
  	float NdotV = dot(surfaceNormal, viewDirection);

  	float s = LdotV - NdotL * NdotV;
  	float t = mix(1.0, max(NdotL, NdotV), step(0.0, s));

  	float sigma2 = roughness * roughness;
  	float A = 1.0 + sigma2 * (albedo / (sigma2 + 0.13) + 0.5 / (sigma2 + 0.33));
  	float B = 0.45 * sigma2 / (sigma2 + 0.09);

  	return diffuseColor * albedo * (A + B * s / t) * RECIPROCAL_PI;
	
}

vec3 F_Schlick( const in vec3 specularColor, const in float dotLH )
{

	// Original approximation by Christophe Schlick '94
	//;float fresnel = pow( 1.0 - dotLH, 5.0 );

	// Optimized variant (presented by Epic at SIGGRAPH '13)
	float fresnel = exp2( ( -5.55473 * dotLH - 6.98316 ) * dotLH );

	return ( 1.0 - specularColor ) * fresnel + specularColor;

}

float G_GGX_SmithCorrelated( const in float alpha, const in float dotNL, const in float dotNV )
{

	float a2 = pow2( alpha );

	// dotNL and dotNV are explicitly swapped. This is not a mistake.
	float gv = dotNL * sqrt( a2 + ( 1.0 - a2 ) * pow2( dotNV ) );
	float gl = dotNV * sqrt( a2 + ( 1.0 - a2 ) * pow2( dotNL ) );

	return 0.5 / max( gv + gl, EPSILON );
}

float D_GGX( const in float alpha, const in float dotNH )
{

	float a2 = pow2( alpha );

	float denom = pow2( dotNH ) * ( a2 - 1.0 ) + 1.0; // avoid alpha = 0 with dotNH = 1

	return RECIPROCAL_PI * a2 / pow2( denom );

}

// GGX Distribution, Schlick Fresnel, GGX-Smith Visibility
vec3 BRDF_Specular_GGX( vec3 lightDirection, vec3 normal, vec3 viewDirection, vec3 specularColor, float roughness )
{

	float alpha = pow2( roughness ); // UE4's roughness

	vec3 halfDir = normalize( lightDirection + viewDirection );

	float dotNL = saturate( dot( normal, lightDirection ) );
	float dotNV = saturate( dot( normal, viewDirection ) );
	float dotNH = saturate( dot( normal, halfDir ) );
	float dotLH = saturate( dot( lightDirection, halfDir ) );

	vec3 F = F_Schlick( specularColor, dotLH );

	float G = G_GGX_SmithCorrelated( alpha, dotNL, dotNV );

	float D = D_GGX( alpha, dotNH );

	return F * ( G * D );

}

vec3 RE_Direct_Standard( vec3 lightDirection, vec3 lightColor, vec3 normal, vec3 viewDirection, vec3 diffuseColor, vec3 specularColor, float roughness )
{

	float dotNL = saturate( dot( normal, lightDirection ) );

	vec3 irradiance = dotNL * lightColor;
	
	vec3 reflectedLight = vec3(0.0);


		irradiance *= PI; // punctual light


	//reflectedLight += irradiance * BRDF_Diffuse_Lambert( diffuseColor );
	
	reflectedLight += irradiance * BRDF_Diffuse_OrenNayar( lightDirection, normal, viewDirection, diffuseColor, roughness, 1.0 );

	//reflectedLight += irradiance * BRDF_Specular_GGX( lightDirection, normal, viewDirection, specularColor, roughness );
	
	return reflectedLight;

}

bool testLightInRange( const in float lightDistance, const in float cutoffDistance )
{

	return any( bvec2( cutoffDistance == 0.0, lightDistance < cutoffDistance ) );

}

float punctualLightIntensityToIrradianceFactor( const in float lightDistance, const in float cutoffDistance, const in float decayExponent )
{
	
	float distanceFalloff = 1.0 / max( pow( lightDistance, decayExponent ), 0.01 );
	float maxDistanceCutoffFactor = pow2( saturate( 1.0 - pow4( lightDistance / cutoffDistance ) ) );
	return distanceFalloff * maxDistanceCutoffFactor;
	
}


// shading
vec3 shading( vec3 p, vec3 n, vec3 eyePos, mat3 materialMatrix, float materialID, bool doShadows )
{
	
	// material
	vec3 mDiff = vec3( materialMatrix[0][0], materialMatrix[0][1], materialMatrix[0][2] );
	vec3 mSpec = vec3(0.0);
	float metalnessFactor = materialMatrix[1][0];
	float roughness = materialMatrix[1][1];
	roughness = clamp( roughness, 0.04, 1.0 );
	
	mDiff *= ( 1.0 - metalnessFactor );
	mSpec = mix( vec3( 0.04 ), mDiff, metalnessFactor );
	
	vec3 viewDirection = normalize( eyePos - p );
	vec3 ambient = vec3( 0.0 );
	vec3 directLightColor = vec3( 0.0 );
	vec3 totalReflectedLight = vec3( 0.0 );
	
	// do checkerBoard pattern on floor
	if ( materialID == 0.0 )
	{
		// infinite plane
		float pattern = clamp( chessBoard(p, 0.5), 0.3, 1.0 );
		
		// for a bounded plane
		//if ( abs(pos.x) > 8.0 || abs(pos.z) > 8.0 )
		//	pattern = 0.0;
    		//else pattern = clamp( chessBoard(p, 0.5), 0.3, 1.0 );
		
		mDiff *= pattern;
	}

	// light 0
	{
		vec3 lightDirection = lightPos[0] - p;
		float lightDistance = length( lightDirection );
		lightDirection = normalize( lightDirection );
		
		float shadow = 1.0;
		if (doShadows) 
			shadow = softShadow( p, lightDirection );
			
		if ( testLightInRange( lightDistance, 100.0 ) ) 
		{
			directLightColor = light00Color;
			//test
			//directLightColor = vec3(1.0);
			
			directLightColor *= punctualLightIntensityToIrradianceFactor( lightDistance, 100.0, 2.0 );
			directLightColor *= shadow;
		} else
		{
			directLightColor = vec3( 0.0 );
		}
		
		totalReflectedLight += RE_Direct_Standard( lightDirection, directLightColor, n, viewDirection, mDiff, mSpec, roughness );			
	}
	
	// light 1
	{
		vec3 lightDirection = lightPos[1] - p;
		float lightDistance = length( lightDirection );
		lightDirection = normalize( lightDirection );
		
		float shadow = 1.0;
		if (doShadows) 
			shadow = softShadow( p, lightDirection );
			
		if ( testLightInRange( lightDistance, 100.0 ) ) 
		{
			directLightColor = light01Color;
			directLightColor *= punctualLightIntensityToIrradianceFactor( lightDistance, 100.0, 2.0 );
			directLightColor *= shadow;
		} else
		{
			directLightColor = vec3( 0.0 );
		}
		
		totalReflectedLight += RE_Direct_Standard( lightDirection, directLightColor, n, viewDirection, mDiff, mSpec, roughness );			
	}
	
	// light 2
	{
		vec3 lightDirection = lightPos[2] - p;
		float lightDistance = length( lightDirection );
		lightDirection = normalize( lightDirection );
		
		float shadow = 1.0;
		if (doShadows) 
			shadow = softShadow( p, lightDirection );
			
		if ( testLightInRange( lightDistance, 100.0 ) ) 
		{
			directLightColor = light02Color;
			directLightColor *= punctualLightIntensityToIrradianceFactor( lightDistance, 100.0, 2.0 );
			directLightColor *= shadow;
		} else
		{
			directLightColor = vec3( 0.0 );
		}
		
		totalReflectedLight += RE_Direct_Standard( lightDirection, directLightColor, n, viewDirection, mDiff, mSpec, roughness );			
	}
	
	return totalReflectedLight;
}

vec3 getPixelColor( vec2 camUV, vec3 camPos, vec3 rayDir )
{
	mat3 materialMatrix;
	
	vec3 normal = vec3( 0.0 );
	
	vec3 reflectedPos = vec3( 0.0 );
	vec3 reflectionNormal = vec3( 0.0 );
	vec3 reflectedDir = vec3( 0.0 );
	vec3 reflectedColor = vec3( 0.0 );
	
	vec3 refractedPos = vec3( 0.0 );
	vec3 refractionNormal = vec3( 0.0 );
	vec3 refractedDir = vec3( 0.0 );
	vec3 refractedColor = vec3( 0.0 );
	
	vec3 specularReflectDir = vec3( 0.0 );
	vec3 diffuseReflectDir = vec3( 0.0 );
	
	vec3 pixelColor = vec3( 0.0 );
	
	float roughness = 0.0;
	float opacity = 0.0;
	float refractionRatio = 0.0;
	float distFromCamera = 0.0;
	float reflectedDistFromCamera = 0.0;
	
	// initial raymarching (raycast)
	float delta00 = 0.1;
	vec2 res00 = vec2( 0.0 );
	
	for( int i = 0; i < MAX_ITERATIONS; i++ ) 
	{
		res00 = getDistToNearestObj( camPos + rayDir * delta00, true );
		if ( res00.x < EPSILON || delta00 > MAX_RENDER_DISTANCE ) break;
		//if ( res00.x < EPSILON ) break;
		delta00 += res00.x;
	}
	
	// check if we hit a light source
	if ( res00.y == -1.0 ) return light00Color / uLightMatrix[0][0][3];
	if ( res00.y == -2.0 ) return light01Color / uLightMatrix[1][0][3];
	if ( res00.y == -3.0 ) return light02Color / uLightMatrix[2][0][3];

    	vec3 pos = camPos + rayDir * delta00;
	
	// first check if the ray didn't hit anything
	distFromCamera = length( pos - camPos );
	
	if ( distFromCamera > MAX_RENDER_DISTANCE )
	{
		pixelColor = vec3(0.0);
		return pixelColor;
	}
	
	// get current material and its properties
	materialMatrix = getMaterialMatrix( res00.y );
	roughness = materialMatrix[1][1];
	opacity = materialMatrix[1][2];
	refractionRatio = materialMatrix[2][0];
	
	normal = computeSurfaceNormal( pos );
		
    	// compute first intersection material color	
	reflectedColor += opacity * shading( pos, normal, camPos, materialMatrix, res00.y, true );
		
	// REFLECTION
		
	// compute reflected color
	specularReflectDir = reflect(rayDir, normal);
	diffuseReflectDir = cosWeightedRandomHemisphereDirection( normal, camUV );
			
	reflectedDir = mix( specularReflectDir, diffuseReflectDir, roughness * 0.1 );
			
	// reflection raymarching
	float delta01 = 0.01;
	vec2 res01 = vec2( 0.0 );
	
    	for( int i = 0; i < MAX_REFLECTION_ITERATIONS; i++ ) 
	{
        	res01 = getDistToNearestObj( pos + reflectedDir * delta01, true );
		if ( res01.x < EPSILON ) break;
        	delta01 += res01.x;
    	}
	
			
	reflectedPos = pos + reflectedDir * delta01;
	
	// first check if the ray didn't hit anything
	reflectedDistFromCamera = length( reflectedPos - pos );
	
	if ( reflectedDistFromCamera > MAX_RENDER_DISTANCE )
	{
		res01.y = -5.0;
	}
	
	// check if we hit a light source
	if ( res01.y == -1.0 ) reflectedColor += ( light00Color / uLightMatrix[0][0][3] );
	if ( res01.y == -2.0 ) reflectedColor += ( light01Color / uLightMatrix[1][0][3] );
	if ( res01.y == -3.0 ) reflectedColor += ( light02Color / uLightMatrix[2][0][3] );
			
	if ( res01.y >= 0.0 )
	{
		// get current material
		materialMatrix = getMaterialMatrix( res01.y );

		reflectionNormal = computeSurfaceNormal( reflectedPos );
		
		reflectedColor += 0.5 * shading( reflectedPos, reflectionNormal, pos, materialMatrix, res01.y, false );
		
		if ( res00.y == 4.0 ) 
			reflectedColor *= vec3(0.0,0.06,0.06);
	}
	
		
	// REFRACTION
	if (refractionRatio != 0.98)
	{
		
		// we are entering the glass material
		refractedDir = refract(rayDir, normal, refractionRatio);
		
		// refraction raymarching entering
		float delta02 = 0.01;
		vec2 res02 = vec2( 0.0 );
			
		// trace until we hit the back inside of object
		for( int i = 0; i < MAX_REFLECTION_ITERATIONS; i++ ) 
		{
        		res02 = getDistToNearestObj( pos + refractedDir * delta02, false );
			delta02 -= res02.x;
			//if ( -res02.x > -EPSILON ) break;		
    		}
			
		// we are now exiting the glass material
		refractedPos = pos + refractedDir * delta02;	
		refractionNormal = computeSurfaceNormal( refractedPos );
			
		refractedDir = refract(refractedDir, -refractionNormal, 1.0 / refractionRatio);
			
		// TODO get weighted random sample and mix with roughness like above (in reflection routine)
		
		// refraction raymarching exiting
		float delta03 = 0.01;
		vec2 res03 = vec2( 0.0 );
	
		// trace until we hit another world object and get its color
    		for( int i = 0; i < MAX_REFLECTION_ITERATIONS; i++ ) 
		{
        		res03 = getDistToNearestObj( refractedPos + refractedDir * delta03, false );
			//if ( res03.x < EPSILON || delta03 > MAX_RENDER_DISTANCE ) break;
			if ( res03.x < EPSILON ) break;
			delta03 += res03.x;
    		}
			
		refractedPos = refractedPos + refractedDir * delta03;
		
		// first check if the ray didn't hit anything
		reflectedDistFromCamera = length( refractedPos - pos );
	
		if ( reflectedDistFromCamera > MAX_RENDER_DISTANCE )
		{
			res03.y = -5.0;
		}
		
		// check if we hit a light source
		if ( res03.y == -1.0 ) refractedColor += ( light00Color / uLightMatrix[0][0][3] );
		if ( res03.y == -2.0 ) refractedColor += ( light01Color / uLightMatrix[1][0][3] );
		if ( res03.y == -3.0 ) refractedColor += ( light02Color / uLightMatrix[2][0][3] );
	
		if ( res03.y >= 0.0 )
		{
			// get current material
			materialMatrix = getMaterialMatrix( res03.y );

			refractionNormal = computeSurfaceNormal( refractedPos );
	
			refractedColor = shading( refractedPos, refractionNormal, pos, materialMatrix, res03.y, false );
			
			//TODO the following is not physically correct, just something to be able to see both colors
			// refracted glass material also gives a green tint to the transmitted ray 
			refractedColor *= vec3(0.0,0.5,0.5);
			reflectedColor = mix(reflectedColor, refractedColor,0.9);
				
		}
					  
	}
	

	pixelColor = reflectedColor;
	
	// color intensity is attenuated by distance from camera
	pixelColor = mix( vec3(0.0,0.0,0.0), pixelColor, exp2( -distFromCamera * 0.05 ) );
	
	//pixelColor = clamp( pixelColor, 0.0, 1.0 );
	
	return pixelColor;
	
}


void main( void )
{

	vec2 screenPos = gl_FragCoord.xy / resolution.xy;
	vec2 camUV = screenPos * 2.0 - 1.0;
	vec3 camPos = vec3(uCameraMatrix[3][0], uCameraMatrix[3][1], uCameraMatrix[3][2]);
	
    	vec3 camRight   = ( vec3( uCameraMatrix[0][0],  uCameraMatrix[0][1],  uCameraMatrix[0][2]) );
    	vec3 camUp      = ( vec3( uCameraMatrix[1][0],  uCameraMatrix[1][1],  uCameraMatrix[1][2]) );
	vec3 camForward = ( vec3(-uCameraMatrix[2][0], -uCameraMatrix[2][1], -uCameraMatrix[2][2]) );
	
    	vec3 rayDir = normalize(camUV.x * camRight * uULen + camUV.y * camUp * uVLen + camForward);
	// jittering
	rayDir += ( vec3( hash11(sin(time+screenPos.x)), hash11(cos(time+screenPos.y)), hash11(cos(time+screenPos.x * screenPos.y)) ) * 0.003 );
	//camPos += ( vec3( hash11(sin(time)), hash11(cos(time)), hash11(sin(time)) ) * 0.01 );
	//camPos += ( vec3( 0.0, hash11(cos(time)), hash11(sin(time)) ) * 0.006 );
	
	
	lightPos[0] = vec3(uLightMatrix[0][0][0], uLightMatrix[0][0][1], uLightMatrix[0][0][2]);
	lightPos[1] = vec3(uLightMatrix[1][0][0], uLightMatrix[1][0][1], uLightMatrix[1][0][2]);
	lightPos[2] = vec3(uLightMatrix[2][0][0], uLightMatrix[2][0][1], uLightMatrix[2][0][2]);
	
	light00Color = uLightMatrix[0][0][3] * vec3( uLightMatrix[0][1][0], uLightMatrix[0][1][1], uLightMatrix[0][1][2] );
    	light01Color = uLightMatrix[1][0][3] * vec3( uLightMatrix[1][1][0], uLightMatrix[1][1][1], uLightMatrix[1][1][2] );
	light02Color = uLightMatrix[2][0][3] * vec3( uLightMatrix[2][1][0], uLightMatrix[2][1][1], uLightMatrix[2][1][2] );
	
	
	// perform path tracing (via RayMarching) and get resulting pixel color
	vec3 pixelColor = getPixelColor(camUV, camPos, rayDir);
	
	
	// post processing
	
	// Gamma correction
	vec3 finalColor = sqrt( pixelColor ); 
	//finalColor = pow( pixelColor, vec3( 1.0 / screenGamma ) );
		
    	finalColor = mix( finalColor, texture2D(tPreviousTexture, vUv).rgb, min(uFrameCounter, 0.98) );
	
	// Slowest Converging, Max Motion Blur if animated
	//finalColor = ( texture2D(tPreviousTexture, vUv).rgb * clamp(uFrameCounter, 0.0, 0.92) ) + ( finalColor * max(1.0-uFrameCounter, 0.1) );
	
	// Slow Converging, Motion Blur if animated
	//finalColor = (texture2D(tPreviousTexture, vUv).rgb * 0.91) + (finalColor * 0.1);
	
	// Fast Converging, slight Motion Blur
	//finalColor = (texture2D(tPreviousTexture, vUv).rgb * 0.8) + (finalColor * 0.2);
	
	// Fastest Converging, almost no Motion Blur
	//finalColor = (texture2D(tPreviousTexture, vUv).rgb * 0.5) + (finalColor * 0.5);
	
	gl_FragColor = vec4(finalColor,1.0);
}

		</script>
		
		
		<script>

			if ( ! Detector.webgl ) Detector.addGetWebGLMessage();

			var container, stats;
			var rttGeometry, rttMaterial, rttMesh; // rtt = render to texture
			var screenGeometry, screenMaterial, screenMesh;
			var groundGeometry, checkeredMaterial, groundMesh;
			var boxGeometry, blueMaterial, boxMesh;
			var sphereGeometry, mirrorMaterial, whiteMaterial, glassMaterial;
			var sphereMesh = [];
			var pointLight00, pointLight01, pointLight02;
			var quadCamera, rttCamera;
			var renderer, clock;
			var rttPathTraceTexture, rttScreenOutputTexture, sceneScreen, sceneRTT; // RTT = Render To Texture
			var windowWidth, windowHeight;
			var fovScale;
			var frameTime, elapsedTime;
			var rttUniforms;
			var pixelRatio = 0.5;
			var TWO_PI = Math.PI * 2;
			var rotationalAmount = 2.0;
			var rotationalAxis = new THREE.Vector3(0,1,0);
			var cameraDirectionVec = new THREE.Vector3();
			var swap = false;
			var clearScreenFlag = false;
			var frameCounter = 0.5;
			
			
			init();
			animate();

			function init() {

				container = document.getElementById( 'container' );
				renderer = new THREE.WebGLRenderer();
				//renderer.autoClear = false;
				// 1 is full resolution, 0.5 is half, 0.25 is quarter, etc. (must be > than 0.0)
				renderer.setPixelRatio(pixelRatio);
				
				container.appendChild( renderer.domElement );

				stats = new Stats();
				stats.domElement.style.position = 'absolute';
				stats.domElement.style.top = '0px';
				container.appendChild( stats.domElement );

				
				
				window.addEventListener( 'resize', onWindowResize, false );
				
				clock = new THREE.Clock();
				
				sceneRTT = new THREE.Scene();
				sceneScreen = new THREE.Scene();
				
				rttPathTraceTexture = new THREE.WebGLRenderTarget( window.innerWidth * pixelRatio, window.innerHeight * pixelRatio, {
					minFilter: THREE.NearestFilter, // default THREE.LinearMipMapLinearFilter
					magFilter: THREE.NearestFilter, // default THREE.LinearFilter
					format: THREE.RGBFormat,
					depthBuffer: false,
					stencilBuffer: false
				} );
				
				rttScreenOutputTexture = new THREE.WebGLRenderTarget( window.innerWidth * pixelRatio, window.innerHeight * pixelRatio, {
					minFilter: THREE.NearestFilter, 
					magFilter: THREE.NearestFilter, 
					format: THREE.RGBFormat,
					depthBuffer: false,
					stencilBuffer: false
				} );
				
				rttPathTraceTexture.texture.generateMipmaps = false;
				rttScreenOutputTexture.texture.generateMipmaps = false;
				
				// quadCamera is simply the camera to help render the full screen quad (2 triangles),
				// hence the name.  It is an Orthographic camera that sits facing the view plane, which serves as
				// the window into our 3d world. This camera will not move or rotate for the duration of the app.
				quadCamera = new THREE.OrthographicCamera( -1, 1, 1, -1, 0, 1 );
				sceneScreen.add(quadCamera);
				
				// rttCamera is the dynamic camera 3d object that will be positioned, oriented and 
				// constantly updated inside the 3d scene.  Its view will ultimately get passed back to the 
				// stationary quadCamera, which renders the scene to a fullscreen quad (made up of 2 large triangles).
				rttCamera = new THREE.PerspectiveCamera(50, window.innerWidth / window.innerHeight, 1, 1000);
				sceneRTT.add(rttCamera);
				//rttCamera.position.set(0,1,5);
				//rttCamera.lookAt(new THREE.Vector3(0,0,-1));
				
				rttGeometry = new THREE.PlaneBufferGeometry( 2, 2 );

				rttUniforms = {
					tPreviousTexture: { type: "t", value: rttScreenOutputTexture },
					resolution: { type: "v2", value: new THREE.Vector2() },
					
					time: { type: "f", value: 0.0 },
					uFrameCounter: { type: "f", value: 0.0 },
					uULen: { type: "f", value: 1.0 },
					uVLen: { type: "f", value: 1.0 },
					
					uCheckeredMaterialMatrix: { type: "m3", value: new THREE.Matrix3() },
					uMirrorMaterialMatrix: { type: "m3", value: new THREE.Matrix3() },
					uBlueMaterialMatrix: { type: "m3", value: new THREE.Matrix3() },
					uWhiteMaterialMatrix: { type: "m3", value: new THREE.Matrix3() },
					uGlassMaterialMatrix: { type: "m3", value: new THREE.Matrix3() },
					
					uBoxMeshMatrix: { type: "m4", value: new THREE.Matrix4() },
					uCameraMatrix: { type: "m4", value: new THREE.Matrix4() },
					
					uSphereMeshMatrix: { type: "m4v", value: [] },
					uLightMatrix: { type: "m4v", value: [] }
				};
			
				rttMaterial = new THREE.ShaderMaterial( {
					uniforms: rttUniforms,
					vertexShader: document.getElementById( 'renderToTextureVertexShader' ).textContent,
					fragmentShader: document.getElementById( 'renderToTextureFragmentShader' ).textContent,
				        depthTest: false,
                                        depthWrite: false
                                } );

				rttMesh = new THREE.Mesh( rttGeometry, rttMaterial );
				sceneRTT.add( rttMesh );

				
				// Ground
				groundGeometry = new THREE.PlaneBufferGeometry(1000, 1000, 1, 1);
				checkeredMaterial = new THREE.MeshStandardMaterial( {
					color: new THREE.Color(0.8, 0.8, 0.8), //RGB, ranging from 0.0 - 1.0
					roughness: 0.04,
					metalness: 0.0,
					opacity: 1.0,
					refractionRatio: 0.98
				} );
				
				groundMesh = new THREE.Mesh(groundGeometry, checkeredMaterial);
				// the ground plane is initially in the X-Y plane facing the camera,
				// therefore, we rotate the ground plane to lie flat in the X-Z plane
				groundMesh.rotation.x = Math.PI / -2;
				sceneRTT.add(groundMesh);
				groundMesh.visible = false;
				
				rttUniforms.uCheckeredMaterialMatrix.value.elements[0] = groundMesh.material.color.r;
				rttUniforms.uCheckeredMaterialMatrix.value.elements[1] = groundMesh.material.color.g;
				rttUniforms.uCheckeredMaterialMatrix.value.elements[2] = groundMesh.material.color.b;
				rttUniforms.uCheckeredMaterialMatrix.value.elements[3] = groundMesh.material.metalness;
				rttUniforms.uCheckeredMaterialMatrix.value.elements[4] = groundMesh.material.roughness;
				rttUniforms.uCheckeredMaterialMatrix.value.elements[5] = groundMesh.material.opacity;
				rttUniforms.uCheckeredMaterialMatrix.value.elements[6] = groundMesh.material.refractionRatio;
				
				
				// Boxes
				boxGeometry = new THREE.BoxGeometry(1,1,1);
				blueMaterial = new THREE.MeshStandardMaterial( {
					color: new THREE.Color(0.0, 0.0, 0.99), //RGB, ranging from 0.0 - 1.0
					roughness: 0.1,
					metalness: 0.5,
					opacity: 1.0,
					refractionRatio: 0.98
				} );
				
				boxMesh = new THREE.Mesh(boxGeometry, blueMaterial);
				sceneRTT.add(boxMesh);
				boxMesh.visible = false;
				
				rttUniforms.uBlueMaterialMatrix.value.elements[0] = boxMesh.material.color.r;
				rttUniforms.uBlueMaterialMatrix.value.elements[1] = boxMesh.material.color.g;
				rttUniforms.uBlueMaterialMatrix.value.elements[2] = boxMesh.material.color.b;
				rttUniforms.uBlueMaterialMatrix.value.elements[3] = boxMesh.material.metalness;
				rttUniforms.uBlueMaterialMatrix.value.elements[4] = boxMesh.material.roughness;
				rttUniforms.uBlueMaterialMatrix.value.elements[5] = boxMesh.material.opacity;
				rttUniforms.uBlueMaterialMatrix.value.elements[6] = boxMesh.material.refractionRatio;
				
				
				// Spheres
				mirrorMaterial = new THREE.MeshStandardMaterial( {
					color: new THREE.Color(0.0, 0.0, 0.0), //RGB, ranging from 0.0 - 1.0
					roughness: 0.04,
					metalness: 1.0,
					opacity: 1.0,
					refractionRatio: 0.98
				} );
				whiteMaterial = new THREE.MeshStandardMaterial( {
					color: new THREE.Color(0.99, 0.99, 0.99), //RGB, from 0.0 - 1.0
					roughness: 0.04,
					metalness: 0.1,
					opacity: 1.0,
					refractionRatio: 0.98
				} );
				glassMaterial = new THREE.MeshStandardMaterial( {
					color: new THREE.Color(0.0, 0.5, 0.5), //RGB, from 0.0 - 1.0
					roughness: 0.04,
					metalness: 0.0,
					opacity: 0.01, // 0.01 almost fully transparent
					refractionRatio: 0.6666 // Air has IndexOfRefraction very near 1.0
							      // Glass has IndexOfRefraction around 1.5
				        		// thus, the refractionRatio is: 1.0 / 1.5 = 0.6666
				} );
				
				
					
				sphereGeometry = new THREE.SphereGeometry(1);
					
				sphereMesh[0] = new THREE.Mesh(sphereGeometry, mirrorMaterial);
				sceneRTT.add(sphereMesh[0]);  sphereMesh[0].visible = false;
				rttUniforms.uSphereMeshMatrix.value[0] = new THREE.Matrix4();
				
				sphereMesh[1] = new THREE.Mesh(sphereGeometry, mirrorMaterial);
				sceneRTT.add(sphereMesh[1]);  sphereMesh[1].visible = false;
				rttUniforms.uSphereMeshMatrix.value[1] = new THREE.Matrix4();
				
				sphereMesh[2] = new THREE.Mesh(sphereGeometry, whiteMaterial);
				sceneRTT.add(sphereMesh[2]);  sphereMesh[2].visible = false;
				rttUniforms.uSphereMeshMatrix.value[2] = new THREE.Matrix4();
				
				sphereMesh[3] = new THREE.Mesh(sphereGeometry, glassMaterial);
				sceneRTT.add(sphereMesh[3]);  sphereMesh[3].visible = false;
				rttUniforms.uSphereMeshMatrix.value[3] = new THREE.Matrix4();
			
				
				rttUniforms.uMirrorMaterialMatrix.value.elements[0] = sphereMesh[0].material.color.r;
				rttUniforms.uMirrorMaterialMatrix.value.elements[1] = sphereMesh[0].material.color.g;
				rttUniforms.uMirrorMaterialMatrix.value.elements[2] = sphereMesh[0].material.color.b;
				rttUniforms.uMirrorMaterialMatrix.value.elements[3] = sphereMesh[0].material.metalness;
				rttUniforms.uMirrorMaterialMatrix.value.elements[4] = sphereMesh[0].material.roughness;
				rttUniforms.uMirrorMaterialMatrix.value.elements[5] = sphereMesh[0].material.opacity;
				rttUniforms.uMirrorMaterialMatrix.value.elements[6] = sphereMesh[0].material.refractionRatio;
				
				rttUniforms.uWhiteMaterialMatrix.value.elements[0] = sphereMesh[2].material.color.r;
				rttUniforms.uWhiteMaterialMatrix.value.elements[1] = sphereMesh[2].material.color.g;
				rttUniforms.uWhiteMaterialMatrix.value.elements[2] = sphereMesh[2].material.color.b;
				rttUniforms.uWhiteMaterialMatrix.value.elements[3] = sphereMesh[2].material.metalness;
				rttUniforms.uWhiteMaterialMatrix.value.elements[4] = sphereMesh[2].material.roughness;
				rttUniforms.uWhiteMaterialMatrix.value.elements[5] = sphereMesh[2].material.opacity;
				rttUniforms.uWhiteMaterialMatrix.value.elements[6] = sphereMesh[2].material.refractionRatio;
				
				rttUniforms.uGlassMaterialMatrix.value.elements[0] = sphereMesh[3].material.color.r;
				rttUniforms.uGlassMaterialMatrix.value.elements[1] = sphereMesh[3].material.color.g;
				rttUniforms.uGlassMaterialMatrix.value.elements[2] = sphereMesh[3].material.color.b;
				rttUniforms.uGlassMaterialMatrix.value.elements[3] = sphereMesh[3].material.metalness;
				rttUniforms.uGlassMaterialMatrix.value.elements[4] = sphereMesh[3].material.roughness;
				rttUniforms.uGlassMaterialMatrix.value.elements[5] = sphereMesh[3].material.opacity;
				rttUniforms.uGlassMaterialMatrix.value.elements[6] = sphereMesh[3].material.refractionRatio;
				
				
				// TODO make lights.visible = false?
				// Lights
				// Blue light
				pointLight00 = new THREE.PointLight('rgb(0,0,255)', 1, 100, 2);
				pointLight00.power = 40;
				sceneRTT.add(pointLight00);
				// White light
				pointLight01 = new THREE.PointLight('rgb(255,255,255)', 1, 100, 2);
				pointLight01.power = 40;
				sceneRTT.add(pointLight01);
				// Red light
				pointLight02 = new THREE.PointLight('rgb(255,0,0)', 1, 100, 2);
				pointLight02.power = 40;
				sceneRTT.add(pointLight02);
				
				
				rttUniforms.uLightMatrix.value[0] = new THREE.Matrix4();
				rttUniforms.uLightMatrix.value[1] = new THREE.Matrix4();
				rttUniforms.uLightMatrix.value[2] = new THREE.Matrix4();
				
				
				rttUniforms.uLightMatrix.value[0].elements[3] = pointLight00.power;
				rttUniforms.uLightMatrix.value[0].elements[4] = pointLight00.color.r;
				rttUniforms.uLightMatrix.value[0].elements[5] = pointLight00.color.g;
				rttUniforms.uLightMatrix.value[0].elements[6] = pointLight00.color.b;
				rttUniforms.uLightMatrix.value[0].elements[7] = pointLight00.intensity;
				rttUniforms.uLightMatrix.value[0].elements[8] = pointLight00.distance;
				
				rttUniforms.uLightMatrix.value[1].elements[3] = pointLight01.power;
				rttUniforms.uLightMatrix.value[1].elements[4] = pointLight01.color.r;
				rttUniforms.uLightMatrix.value[1].elements[5] = pointLight01.color.g;
				rttUniforms.uLightMatrix.value[1].elements[6] = pointLight01.color.b;
				rttUniforms.uLightMatrix.value[1].elements[7] = pointLight01.intensity;
				rttUniforms.uLightMatrix.value[1].elements[8] = pointLight01.distance;
				
				rttUniforms.uLightMatrix.value[2].elements[3] = pointLight02.power;
				rttUniforms.uLightMatrix.value[2].elements[4] = pointLight02.color.r;
				rttUniforms.uLightMatrix.value[2].elements[5] = pointLight02.color.g;
				rttUniforms.uLightMatrix.value[2].elements[6] = pointLight02.color.b;
				rttUniforms.uLightMatrix.value[2].elements[7] = pointLight02.intensity;
				rttUniforms.uLightMatrix.value[2].elements[8] = pointLight02.distance;
				
				
				screenGeometry = new THREE.PlaneBufferGeometry( 2, 2 );
				
				screenMaterial = new THREE.ShaderMaterial( {
					uniforms: { tTexture0: { type: "t", value: rttPathTraceTexture },
						    //tTexture1: { type: "t", value: rttScreenOutputTexture }
						  },
					vertexShader: document.getElementById( 'screenVertexShader' ).textContent,
					fragmentShader: document.getElementById( 'screenFragmentShader' ).textContent,
					depthWrite: false,
					depthTest: false
				} );
				
				screenMesh = new THREE.Mesh(screenGeometry, screenMaterial);
				sceneScreen.add(screenMesh);
				
				// this must be at the end of the init() function
				onWindowResize();
				

			}
			
			

			function onWindowResize( event ) {

				rttUniforms.resolution.value.x = window.innerWidth * pixelRatio;
				rttUniforms.resolution.value.y = window.innerHeight * pixelRatio;
				
				rttPathTraceTexture.setSize( window.innerWidth * pixelRatio, window.innerHeight * pixelRatio );
				rttScreenOutputTexture.setSize( window.innerWidth * pixelRatio, window.innerHeight * pixelRatio );
				
				rttCamera.aspect = window.innerWidth / window.innerHeight;
				rttCamera.updateProjectionMatrix();
				
				// the following scales all scene objects by the rttCamera's field of view,
				// taking into account the screen aspect ratio and multiplying the uniform uULen,
				// the x-coordinate, by this ratio
				fovScale = rttCamera.fov * 0.5 * (Math.PI / 180.0);
				rttUniforms.uVLen.value = Math.tan(fovScale);
				rttUniforms.uULen.value = rttUniforms.uVLen.value * rttCamera.aspect;

				renderer.setSize( window.innerWidth, window.innerHeight );
				
				
			}
			

			var stopTime = 10.0;

			function animate() {

				requestAnimationFrame( animate );

				frameTime = clock.getDelta();
				elapsedTime = clock.getElapsedTime() % 1000;
				
				frameCounter += 0.01;
				
				rttUniforms.time.value = elapsedTime;
				
				rttUniforms.uFrameCounter.value = frameCounter;
				
				
				// just testing progressiveness of PathTracing
				if (frameCounter > 4.0) {
					stopTime += 2.0;
					clearScreenFlag = true;
					frameCounter = 0.5;
				}
				elapsedTime = stopTime;
						
			
				// LIGHTS
				pointLight00.position.set( Math.sin(elapsedTime * 0.2)*10.0, 4.0, -5.0);
				rttUniforms.uLightMatrix.value[0].elements[0] = pointLight00.position.x;
				rttUniforms.uLightMatrix.value[0].elements[1] = pointLight00.position.y;
				rttUniforms.uLightMatrix.value[0].elements[2] = pointLight00.position.z;
				
				pointLight01.position.set( Math.sin(elapsedTime * 0.4)*-10.0, 4.0, 5.0);
				rttUniforms.uLightMatrix.value[1].elements[0] = pointLight01.position.x;
				rttUniforms.uLightMatrix.value[1].elements[1] = pointLight01.position.y;
				rttUniforms.uLightMatrix.value[1].elements[2] = pointLight01.position.z;
				
				pointLight02.position.set( 3.0, 4.0, Math.sin(elapsedTime * 0.3)*-10.0);
				rttUniforms.uLightMatrix.value[2].elements[0] = pointLight02.position.x;
				rttUniforms.uLightMatrix.value[2].elements[1] = pointLight02.position.y;
				rttUniforms.uLightMatrix.value[2].elements[2] = pointLight02.position.z;
				
				
				
				// BOXES
				boxMesh.position.set(-1.0, 1.0, Math.sin(elapsedTime*0.4)*5.0);
				boxMesh.rotation.set(0, elapsedTime * 0.5, 0);
				///boxMesh.updateMatrixWorld(true);
				// The following matrix will be used inside the raymarcher's distance estimator.
				// It moves the intersection Ray (of the raymarcher) into this object's own space. 
				rttUniforms.uBoxMeshMatrix.value.getInverse(boxMesh.matrixWorld);

				
				// SPHERES
				sphereMesh[0].position.set(0, 0.9 + Math.abs(Math.sin(elapsedTime)) * 3.0, 0);
				sphereMesh[1].position.set( (Math.cos(elapsedTime)) * 4.0, 0.5, 0 );
				sphereMesh[2].position.set( Math.sin(elapsedTime) * 3.0, 1.5, Math.cos(elapsedTime) * 3.0 );
				sphereMesh[3].position.set( Math.cos(elapsedTime) * 2.0, 1.0, Math.sin(elapsedTime) * 2.0 );
				///sphereMesh[0].updateMatrixWorld(true);
				///sphereMesh[1].updateMatrixWorld(true);
				///sphereMesh[2].updateMatrixWorld(true);
				///sphereMesh[3].updateMatrixWorld(true);
				rttUniforms.uSphereMeshMatrix.value[0].getInverse(sphereMesh[0].matrixWorld);
				rttUniforms.uSphereMeshMatrix.value[1].getInverse(sphereMesh[1].matrixWorld);
				rttUniforms.uSphereMeshMatrix.value[2].getInverse(sphereMesh[2].matrixWorld);
				rttUniforms.uSphereMeshMatrix.value[3].getInverse(sphereMesh[3].matrixWorld);
				

				// CAMERA
				rttCamera.position.set( (Math.sin(elapsedTime * 0.25)) * 8, 3 + (2.5 * Math.sin(elapsedTime * 0.2)), 1 );
				//rttCamera.position.set( 0, 0, (Math.sin(elapsedTime)) * 10.0 + 10.0 );
				//rttCamera.position.set( (Math.sin(elapsedTime * 0.2)) * 10.0, 4, (Math.cos(elapsedTime * 0.2)) * 10.0 );
				
				if (clearScreenFlag) {
					rttCamera.position.set(10000,10000,10000);
					clearScreenFlag = false;
				}
				//rttCamera.lookAt(boxMesh.position);
				rttCamera.lookAt(sceneRTT.position);
				//rttCamera.updateMatrixWorld(true);
				
				rttUniforms.uCameraMatrix.value.copy(rttCamera.matrixWorld);
				
                       		
				// RENDERING in 3 steps
				
				// STEP 1
				// Perform PathTracing and Render into rttPathTraceTexture
				// Read previous rttScreenOutputTexture to use as a new starting point to blend with
				renderer.render( sceneRTT, rttCamera, rttPathTraceTexture );
				
				// STEP 2
				// Render full screen quad with generated texture
				// This will be shown on the screen as the final scene output
				renderer.render( sceneScreen, quadCamera );
				
				// STEP 3
				// Also render(save) the final scene output into rttScreenOutputTexture
				// This will be used as a new starting point for Step 1 above
				renderer.render( sceneScreen, quadCamera, rttScreenOutputTexture );
				
				
				stats.update();

			}

		</script>

	</body>
</html>
